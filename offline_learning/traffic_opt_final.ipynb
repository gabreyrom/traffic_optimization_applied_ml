{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import math\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from collections import defaultdict\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import LineString, MultiLineString\n",
    "import networkx as nx\n"
   ],
   "id": "37a1920e2f31b53c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Path to your shapefile\n",
    "path = \"../trimmed_manhattan_shape/trimmed_manhattan.shp\"\n",
    "\n",
    "gdf = gpd.read_file(path)\n",
    "\n",
    "print(\"CRS:\", gdf.crs)\n",
    "print(\"Geometry types:\", gdf.geom_type.unique())\n",
    "print(\"Columns:\", gdf.columns.tolist())\n",
    "\n",
    "# If CRS is geographic (lat/lon), reproject to EPSG:2263 (NY State Plane)\n",
    "if gdf.crs is not None and gdf.crs.is_geographic:\n",
    "    gdf = gdf.to_crs(epsg=2263)\n",
    "    print(\"Reprojected CRS: \", gdf.crs)\n"
   ],
   "id": "3082383b62fe6168",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Quick sanity plot of the shapefile\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 10), sharey=True)\n",
    "gdf.boundary.plot(ax=ax1, linewidth=1)\n",
    "gdf.plot(ax=ax1, alpha=0.5, color=\"lightblue\", edgecolor=\"black\")\n",
    "ax1.set_title(\"Manhattan Boundary and Background\")\n",
    "\n",
    "gdf.plot(ax=ax2, edgecolor=\"black\", facecolor=\"none\")\n",
    "ax2.set_title(\"Manhattan Boundary only\")\n",
    "\n",
    "plt.show()\n"
   ],
   "id": "ea2075108503f7e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Core types\n",
    "Node = Tuple[float, float]     # (x, y)\n",
    "EdgeId = Tuple[Node, Node]     # directed edge\n",
    "EdgeFlows = Dict[EdgeId, float]\n",
    "\n",
    "@dataclass\n",
    "class Edge:\n",
    "    start: Node\n",
    "    end: Node\n",
    "    length_m: float          # meters\n",
    "    v_free: float            # free-flow speed (m/s)\n",
    "    capacity: float          # max cars that fit on this segment\n",
    "    alpha: float = 0.15\n",
    "    beta: float = 4.0\n",
    "\n",
    "    @property\n",
    "    def free_time(self) -> float:\n",
    "        # free-flow travel time (seconds)\n",
    "        return self.length_m / self.v_free\n",
    "\n",
    "    def travel_time(self, flow: float) -> float:\n",
    "        # BPR-style congestion model\n",
    "        x = flow / self.capacity if self.capacity > 0 else 0.0\n",
    "        return self.free_time * (1.0 + self.alpha * (x ** self.beta))\n",
    "\n",
    "\n",
    "Graph = Dict[Node, List[EdgeId]]\n",
    "\n",
    "@dataclass\n",
    "class TrafficNetwork:\n",
    "    graph: Graph\n",
    "    edges: Dict[EdgeId, Edge]\n"
   ],
   "id": "68e1e5bfc5135ce1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def make_node(x: float, y: float, ndigits: int = 3) -> Node:\n",
    "    # rounding keeps nodes consistent instead of having tiny float differences\n",
    "    return round(x, ndigits), round(y, ndigits)\n"
   ],
   "id": "2e8905a3398556d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- Stochastic edge parameters ---\n",
    "\n",
    "def sample_car_length() -> float:\n",
    "    # lognormal with median around 4.5m\n",
    "    mu = math.log(4.5)\n",
    "    sigma = 0.15\n",
    "    length = random.lognormvariate(mu, sigma)\n",
    "    return max(length, 3.5)  # clamp to > 3.5m\n",
    "\n",
    "\n",
    "def sample_gap() -> float:\n",
    "    # lognormal with median around 1.5m\n",
    "    mu = math.log(1.5)\n",
    "    sigma = 0.25\n",
    "    gap = random.lognormvariate(mu, sigma)\n",
    "    return max(gap, 0.5)\n",
    "\n",
    "\n",
    "def sample_spacing() -> float:\n",
    "    # space per vehicle = car length + gap\n",
    "    return sample_car_length() + sample_gap()\n",
    "\n",
    "\n",
    "def sample_free_speed_time_based() -> float:\n",
    "    \"\"\"\n",
    "    Sample free-flow speed via a lognormal model on time-per-meter.\n",
    "    This gives a fatter tail toward low speeds.\n",
    "    \"\"\"\n",
    "    median_s_per_m = 0.09  # ~40 km/h\n",
    "    mu = math.log(median_s_per_m)\n",
    "    sigma = 0.3            # spread; larger => more slow edges\n",
    "\n",
    "    s_per_m = random.lognormvariate(mu, sigma)  # seconds per meter\n",
    "    v_free = 1.0 / s_per_m                      # m/s\n",
    "\n",
    "    # clamp speeds to a plausible urban range ~ 18–90 km/h\n",
    "    v_free = max(min(v_free, 25.0), 5.0)\n",
    "    return v_free\n"
   ],
   "id": "8071216f5d53f2b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def network_from_streets_gdf(streets_gdf: gpd.GeoDataFrame) -> TrafficNetwork:\n",
    "    graph: Dict[Node, List[EdgeId]] = defaultdict(list)\n",
    "    edges: Dict[EdgeId, Edge] = {}\n",
    "\n",
    "    for idx, row in streets_gdf.iterrows():\n",
    "        geom = row.geometry\n",
    "        if geom is None:\n",
    "            continue\n",
    "\n",
    "        # Handle MultiLineString and LineString\n",
    "        if isinstance(geom, MultiLineString):\n",
    "            line_geoms = list(geom.geoms)\n",
    "        elif isinstance(geom, LineString):\n",
    "            line_geoms = [geom]\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        for line in line_geoms:\n",
    "            coords = list(line.coords)\n",
    "            if len(coords) < 2:\n",
    "                continue\n",
    "\n",
    "            for (x1, y1), (x2, y2) in zip(coords[:-1], coords[1:]):\n",
    "                u = make_node(x1, y1)\n",
    "                v = make_node(x2, y2)\n",
    "\n",
    "                seg = LineString([(x1, y1), (x2, y2)])\n",
    "                length_m = seg.length\n",
    "\n",
    "                # stochastic capacity & free-flow speed\n",
    "                spacing = sample_spacing()                # m per car\n",
    "                capacity = max(length_m / spacing, 1.0)   # cars\n",
    "                v_free = sample_free_speed_time_based()   # m/s\n",
    "\n",
    "                # directed u -> v\n",
    "                e1 = (u, v)\n",
    "                if e1 not in edges:\n",
    "                    edges[e1] = Edge(\n",
    "                        start=u,\n",
    "                        end=v,\n",
    "                        length_m=length_m,\n",
    "                        v_free=v_free,\n",
    "                        capacity=capacity,\n",
    "                    )\n",
    "                    graph[u].append(e1)\n",
    "\n",
    "                # bidirectional by default\n",
    "                e2 = (v, u)\n",
    "                if e2 not in edges:\n",
    "                    edges[e2] = Edge(\n",
    "                        start=v,\n",
    "                        end=u,\n",
    "                        length_m=length_m,\n",
    "                        v_free=v_free,\n",
    "                        capacity=capacity,\n",
    "                    )\n",
    "                    graph[v].append(e2)\n",
    "\n",
    "    return TrafficNetwork(graph=dict(graph), edges=edges)\n"
   ],
   "id": "c1d66529b2b16063",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Build the graph",
   "id": "38702dacf5bf9abb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "manhattan_network = network_from_streets_gdf(gdf)\n",
    "print(f\"# nodes: {len(manhattan_network.graph)}\")\n",
    "print(f\"# edges: {len(manhattan_network.edges)}\")\n"
   ],
   "id": "eb78a67045ba1b7b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Convert to NetworkX (for sanity plots)",
   "id": "fab5c5a1aae7dc99"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def to_networkx(network: TrafficNetwork) -> nx.DiGraph:\n",
    "    G = nx.DiGraph()\n",
    "    for node in network.graph.keys():\n",
    "        G.add_node(node, x=node[0], y=node[1])\n",
    "    for e_id, edge in network.edges.items():\n",
    "        G.add_edge(edge.start, edge.end,\n",
    "                   free_time=edge.free_time,\n",
    "                   capacity=edge.capacity)\n",
    "    return G\n",
    "\n",
    "G_nx = to_networkx(manhattan_network)\n",
    "print(\"# NX nodes:\", G_nx.number_of_nodes(), \"# NX edges:\", G_nx.number_of_edges())\n",
    "\n",
    "pos = {n: (n[0], n[1]) for n in G_nx.nodes()}\n",
    "plt.figure(figsize=(8, 8))\n",
    "nx.draw(G_nx, pos=pos, node_size=1, linewidths=0.1, width=0.1)\n",
    "plt.axis(\"equal\")\n",
    "plt.title(\"Road network graph from trimmed_manhattan.shp\")\n",
    "plt.show()\n"
   ],
   "id": "2a43f880bb51c9e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Agents + OD selection",
   "id": "36b2e1c73542929"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class Agent:\n",
    "    origin: Node\n",
    "    destination: Node\n",
    "    path: List[Node] = None\n"
   ],
   "id": "4d641508315b0c2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def sample_agents_random(network: TrafficNetwork, num_agents: int) -> List[Agent]:\n",
    "    nodes = list(network.graph.keys())\n",
    "    agents: List[Agent] = []\n",
    "    for _ in range(num_agents):\n",
    "        o = random.choice(nodes)\n",
    "        d = random.choice(nodes)\n",
    "        while d == o:\n",
    "            d = random.choice(nodes)\n",
    "        agents.append(Agent(origin=o, destination=d))\n",
    "    return agents\n"
   ],
   "id": "685ee20be733500a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def sample_agents_north_south(network: TrafficNetwork,\n",
    "                               num_agents: int,\n",
    "                               band_split: float = 0.5) -> List[Agent]:\n",
    "    nodes = list(network.graph.keys())\n",
    "    ys = [y for (_, y) in nodes]\n",
    "    y_min, y_max = min(ys), max(ys)\n",
    "    y_mid = y_min + band_split * (y_max - y_min)\n",
    "\n",
    "    north_nodes = [n for n in nodes if n[1] >= y_mid]\n",
    "    south_nodes = [n for n in nodes if n[1] <= y_mid]\n",
    "\n",
    "    assert north_nodes and south_nodes, \"North/south bands are empty – check CRS or band_split.\"\n",
    "\n",
    "    agents: List[Agent] = []\n",
    "    for _ in range(num_agents):\n",
    "        o = random.choice(north_nodes)\n",
    "        d = random.choice(south_nodes)\n",
    "        agents.append(Agent(origin=o, destination=d))\n",
    "    return agents\n"
   ],
   "id": "e1fd830d7b1713c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def pick_north_south_pair(network: TrafficNetwork) -> Tuple[Node, Node]:\n",
    "    nodes = list(network.graph.keys())\n",
    "    ys = [y for (_, y) in nodes]\n",
    "    y_min, y_max = min(ys), max(ys)\n",
    "\n",
    "    # north = 10% top band, south = 10% bottom band\n",
    "    north_nodes = [n for n in nodes if n[1] >= y_min + 0.8 * (y_max - y_min)]\n",
    "    south_nodes = [n for n in nodes if n[1] <= y_min + 0.2 * (y_max - y_min)]\n",
    "\n",
    "    o = random.choice(north_nodes)\n",
    "    d = random.choice(south_nodes)\n",
    "    return o, d\n"
   ],
   "id": "e9ca767b12a43396",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def sample_agents_fixed(network: TrafficNetwork,\n",
    "                        num_agents: int,\n",
    "                        origin: Node,\n",
    "                        destination: Node) -> List[Agent]:\n",
    "    return [Agent(origin=origin, destination=destination) for _ in range(num_agents)]\n"
   ],
   "id": "db372c100da34e2c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dijkstra on TrafficNetwork",
   "id": "76575229a6c35425"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import heapq\n",
    "\n",
    "def dijkstra(network: TrafficNetwork,\n",
    "             source: Node,\n",
    "             target: Node,\n",
    "             edge_flows: EdgeFlows) -> List[Node]:\n",
    "    graph, edges = network.graph, network.edges\n",
    "\n",
    "    dist: Dict[Node, float] = {source: 0.0}\n",
    "    prev: Dict[Node, Node] = {}\n",
    "    pq = [(0.0, source)]\n",
    "    visited = set()\n",
    "\n",
    "    while pq:\n",
    "        d, u = heapq.heappop(pq)\n",
    "        if u in visited:\n",
    "            continue\n",
    "        visited.add(u)\n",
    "\n",
    "        if u == target:\n",
    "            break\n",
    "\n",
    "        for edge_id in graph.get(u, []):\n",
    "            edge = edges[edge_id]\n",
    "            v = edge.end\n",
    "            w = edge.travel_time(edge_flows[edge_id])  # cost depends on current flow\n",
    "            nd = d + w\n",
    "\n",
    "            if v not in dist or nd < dist[v]:\n",
    "                dist[v] = nd\n",
    "                prev[v] = u\n",
    "                heapq.heappush(pq, (nd, v))\n",
    "\n",
    "    if target not in dist:\n",
    "        return []  # no path found\n",
    "\n",
    "    # Reconstruct path\n",
    "    path: List[Node] = []\n",
    "    cur = target\n",
    "    while cur != source:\n",
    "        path.append(cur)\n",
    "        cur = prev[cur]\n",
    "    path.append(source)\n",
    "    path.reverse()\n",
    "    return path\n"
   ],
   "id": "12085ac8c3952dd8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Marginal Cost Dijkstra",
   "id": "8c3c41d0c2e59102"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def dijkstra_ff_marginal_cost(\n",
    "    network: TrafficNetwork,\n",
    "    source: Node,\n",
    "    target: Node,\n",
    "    edge_flows: EdgeFlows\n",
    ") -> List[Node]:\n",
    "    \"\"\"\n",
    "    Ford–Fulkerson style: shortest path where edge weight is\n",
    "    the *marginal increase in global world utility G* if we send\n",
    "    one additional car along that edge.\n",
    "\n",
    "    Edges whose flow >= capacity are treated as 'blocked'.\n",
    "    \"\"\"\n",
    "    graph, edges = network.graph, network.edges\n",
    "\n",
    "    dist: Dict[Node, float] = {source: 0.0}\n",
    "    prev: Dict[Node, Node] = {}\n",
    "    pq = [(0.0, source)]\n",
    "    visited = set()\n",
    "\n",
    "    while pq:\n",
    "        cost_u, u = heapq.heappop(pq)\n",
    "        if u in visited:\n",
    "            continue\n",
    "        visited.add(u)\n",
    "\n",
    "        if u == target:\n",
    "            break\n",
    "\n",
    "        for edge_id in graph.get(u, []):\n",
    "            edge = edges[edge_id]\n",
    "            v = edge.end\n",
    "\n",
    "            # Respect capacity (no residual capacity => no edge)\n",
    "            if edge_flows[edge_id] >= edge.capacity:\n",
    "                continue\n",
    "\n",
    "            # Marginal global cost if we add 1 car on this edge\n",
    "            f_before = edge_flows[edge_id]\n",
    "            marginal = edge_marginal_cost(edge, f_before)\n",
    "\n",
    "            new_cost = cost_u + marginal\n",
    "            if v not in dist or new_cost < dist[v]:\n",
    "                dist[v] = new_cost\n",
    "                prev[v] = u\n",
    "                heapq.heappush(pq, (new_cost, v))\n",
    "\n",
    "    if target not in dist:\n",
    "        return []  # no path\n",
    "\n",
    "    # Reconstruct path\n",
    "    path: List[Node] = []\n",
    "    cur = target\n",
    "    while cur != source:\n",
    "        path.append(cur)\n",
    "        cur = prev[cur]\n",
    "    path.append(source)\n",
    "    path.reverse()\n",
    "    return path"
   ],
   "id": "3cfd5a69e20b16b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def edges_from_path(path: List[Node]) -> List[EdgeId]:\n",
    "    return list(zip(path[:-1], path[1:]))\n"
   ],
   "id": "aaa81fe9905fddc3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "SPA routing: selfish, sequential assignment",
   "id": "c2949ff49f77c7d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def spa_route_all(network: TrafficNetwork,\n",
    "                  agents: List[Agent]) -> Tuple[List[Agent], EdgeFlows]:\n",
    "    edge_flows: EdgeFlows = defaultdict(float)\n",
    "\n",
    "    for agent in agents:\n",
    "        path = dijkstra(network, agent.origin, agent.destination, edge_flows)\n",
    "        agent.path = path\n",
    "\n",
    "        for e in edges_from_path(path):\n",
    "            edge_flows[e] += 1.0  # 1 vehicle per agent\n",
    "\n",
    "    return agents, edge_flows\n"
   ],
   "id": "1f5477212b6da5f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Coin FF Routing",
   "id": "51b4e49f1298e221"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def ff_route_all(network: TrafficNetwork,\n",
    "                      agents: List[Agent]) -> Tuple[List[Agent], EdgeFlows]:\n",
    "    \"\"\"\n",
    "    Ford–Fulkerson–style COIN:\n",
    "    - For each agent, find an augmenting path that minimizes marginal\n",
    "      increase in global cost G (using dijkstra_marginal_cost).\n",
    "    - Push 1 unit of flow along that path.\n",
    "    \"\"\"\n",
    "    edge_flows: EdgeFlows = defaultdict(float)\n",
    "\n",
    "    for agent in agents:\n",
    "        path = dijkstra_ff_marginal_cost(\n",
    "            network,\n",
    "            agent.origin,\n",
    "            agent.destination,\n",
    "            edge_flows\n",
    "        )\n",
    "        agent.path = path\n",
    "\n",
    "        for e in edges_from_path(path):\n",
    "            edge_flows[e] += 1.0\n",
    "\n",
    "    return agents, edge_flows"
   ],
   "id": "8258003434448ad3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "World Utility",
   "id": "610a7425499681ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def total_system_travel_time(network: TrafficNetwork,\n",
    "                             edge_flows: EdgeFlows) -> float:\n",
    "    total = 0.0\n",
    "    for e_id, flow in edge_flows.items():\n",
    "        edge = network.edges[e_id]\n",
    "        total += flow * edge.travel_time(flow)\n",
    "    return total\n"
   ],
   "id": "226381393763fa02",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Fixed OD pair and SPA shortest path (for reward shaping)",
   "id": "9fb410ec5e9ef684"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "origin, destination = pick_north_south_pair(manhattan_network)\n",
    "\n",
    "zero_flows = defaultdict(float)\n",
    "shortest_path = dijkstra(manhattan_network, origin, destination, zero_flows)\n",
    "shortest_edges = set(edges_from_path(shortest_path))\n",
    "\n",
    "print(\"Origin:\", origin)\n",
    "print(\"Destination:\", destination)\n",
    "print(\"Shortest path length (edges):\", len(shortest_path))\n"
   ],
   "id": "7ae74b4041d68fd5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def dist_to_dest(node: Node, dest: Node) -> float:\n",
    "    return math.dist(node, dest)\n"
   ],
   "id": "686f730584616a32",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def edge_marginal_cost(edge: Edge, flow_before: float) -> float:\n",
    "    \"\"\"\n",
    "    Given that 'flow_before' cars already use this edge,\n",
    "    what is the marginal increase in global G if one more car uses it?\n",
    "    \"\"\"\n",
    "    f1 = flow_before\n",
    "    f2 = flow_before + 1\n",
    "\n",
    "    t1 = edge.travel_time(f1)\n",
    "    t2 = edge.travel_time(f2)\n",
    "\n",
    "    G1 = f1 * t1\n",
    "    G2 = f2 * t2\n",
    "\n",
    "    return G2 - G1\n"
   ],
   "id": "a13d7e2cdd2ddc66",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "COIN / RL helpers",
   "id": "40046e0182b48e35"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_neighbors(network: TrafficNetwork, node: Node) -> List[Node]:\n",
    "    return [network.edges[e_id].end for e_id in network.graph.get(node, [])]\n"
   ],
   "id": "8df14691080f5c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def choose_action_eps_greedy(network: TrafficNetwork,\n",
    "                             Q: Dict[Tuple[Node, Node, Node], float],\n",
    "                             state_node: Node,\n",
    "                             dest_node: Node,\n",
    "                             epsilon: float) -> Node:\n",
    "    neighbors = get_neighbors(network, state_node)\n",
    "    if not neighbors:\n",
    "        return state_node  # dead end, stay put (will break later)\n",
    "\n",
    "    # exploration\n",
    "    if random.random() < epsilon:\n",
    "        return random.choice(neighbors)\n",
    "\n",
    "    # exploitation: pick neighbor with highest Q\n",
    "    best_q = None\n",
    "    best_actions = []\n",
    "    for a in neighbors:\n",
    "        key = (state_node, dest_node, a)\n",
    "        q = Q.get(key, 0.0)\n",
    "        if best_q is None or q > best_q:\n",
    "            best_q = q\n",
    "            best_actions = [a]\n",
    "        elif q == best_q:\n",
    "            best_actions.append(a)\n",
    "\n",
    "    return random.choice(best_actions)\n"
   ],
   "id": "7001d4ef5457d5d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "COIN-FF-RL with shaped rewards and fixed OD",
   "id": "43aaec587858198f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train_coin_rl(\n",
    "    network: TrafficNetwork,\n",
    "    episodes: int = 200,\n",
    "    num_agents: int = 100,\n",
    "    od_mode: str = \"north_south\",   # kept for compatibility\n",
    "    alpha: float = 0.1,\n",
    "    gamma: float = 0.95,\n",
    "    epsilon_start: float = 0.9,\n",
    "    epsilon_end: float = 0.05,\n",
    "    max_steps_per_agent: int = 1500\n",
    ") -> Dict[Tuple[Node, Node, Node], float]:\n",
    "    \"\"\"\n",
    "    COIN-style Q-learning with shaped rewards and a fixed origin/destination.\n",
    "\n",
    "    Uses the globally defined `origin`, `destination`, and `shortest_edges`:\n",
    "      - origin, destination: fixed north/south pair\n",
    "      - shortest_edges: edges on the SPA shortest path between origin and destination\n",
    "\n",
    "    Reward combines:\n",
    "      - negative marginal congestion cost (at free-flow),\n",
    "      - progress toward the destination,\n",
    "      - penalty for using SPA-shortest-path edges.\n",
    "\n",
    "    Q[(state_node, dest_node, action_node)] estimates the long-term (shaped)\n",
    "    return of choosing `action_node` from `state_node` when heading to\n",
    "    `dest_node` (here always the fixed `destination`).\n",
    "    \"\"\"\n",
    "    Q: Dict[Tuple[Node, Node, Node], float] = {}\n",
    "\n",
    "    # reward weights (you can tune these)\n",
    "    lambda_cong = 1.0   # weight on marginal congestion cost\n",
    "    lambda_prog = 0.05  # weight on progress toward destination\n",
    "    lambda_sp   = 0.5   # penalty for using SPA shortest-path edges\n",
    "\n",
    "    for ep in range(episodes):\n",
    "        # Linear epsilon decay\n",
    "        epsilon = epsilon_start + (epsilon_end - epsilon_start) * (\n",
    "            ep / max(1, episodes - 1)\n",
    "        )\n",
    "\n",
    "        # Sample agents for this episode: ALL use the fixed OD pair\n",
    "        agents = sample_agents_fixed(network, num_agents, origin, destination)\n",
    "\n",
    "        for agent in agents:\n",
    "            s = agent.origin\n",
    "            d = agent.destination\n",
    "            steps = 0\n",
    "\n",
    "            while s != d and steps < max_steps_per_agent:\n",
    "                neighbors = get_neighbors(network, s)\n",
    "                if not neighbors:\n",
    "                    break  # dead end\n",
    "\n",
    "                a = choose_action_eps_greedy(network, Q, s, d, epsilon)\n",
    "\n",
    "                # find edge\n",
    "                edge_id = (s, a)\n",
    "                if edge_id not in network.edges:\n",
    "                    break\n",
    "\n",
    "                edge = network.edges[edge_id]\n",
    "\n",
    "                # (1) COIN-style congestion term: use free-flow marginal cost\n",
    "                f_before = 0.0\n",
    "                delta_G = edge_marginal_cost(edge, f_before)\n",
    "\n",
    "                # (2) progress term: decrease in distance to destination\n",
    "                old_dist = dist_to_dest(s, d)\n",
    "                new_dist = dist_to_dest(a, d)\n",
    "                progress = old_dist - new_dist  # > 0 if moving closer\n",
    "\n",
    "                # (3) penalty for using SPA shortest-path edges\n",
    "                on_spa_shortest = 1.0 if edge_id in shortest_edges else 0.0\n",
    "\n",
    "                # Combined shaped reward\n",
    "                reward = (\n",
    "                    -lambda_cong * delta_G\n",
    "                    + lambda_prog * progress\n",
    "                    - lambda_sp * on_spa_shortest\n",
    "                )\n",
    "\n",
    "                # next state\n",
    "                s_next = a\n",
    "\n",
    "                # Q-learning update\n",
    "                key = (s, d, a)\n",
    "                old_q = Q.get(key, 0.0)\n",
    "\n",
    "                # best next Q\n",
    "                next_neighbors = get_neighbors(network, s_next)\n",
    "                if next_neighbors:\n",
    "                    max_next_q = max(\n",
    "                        Q.get((s_next, d, a_next), 0.0)\n",
    "                        for a_next in next_neighbors\n",
    "                    )\n",
    "                else:\n",
    "                    max_next_q = 0.0\n",
    "\n",
    "                target = reward + gamma * max_next_q\n",
    "                Q[key] = old_q + alpha * (target - old_q)\n",
    "\n",
    "                # move\n",
    "                s = s_next\n",
    "                steps += 1\n",
    "\n",
    "        print(f\"Episode {ep+1}/{episodes} finished, epsilon={epsilon:.3f}\")\n",
    "\n",
    "    return Q"
   ],
   "id": "d5d3601d3106992a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def route_with_trained_Q(\n",
    "    network: TrafficNetwork,\n",
    "    Q: Dict[Tuple[Node, Node, Node], float],\n",
    "    num_agents: int = 200,\n",
    "    od_mode: str = \"fixed\",\n",
    "    max_steps_per_agent: int = 1500\n",
    ") -> Tuple[List[Agent], EdgeFlows, float]:\n",
    "    \"\"\"\n",
    "    Evaluate a trained Q-table by routing agents and computing the resulting edge flows and G.\n",
    "    By default uses the fixed global (origin, destination); if od_mode == \"north_south\"\n",
    "    you can still sample north-south commuters instead.\n",
    "    \"\"\"\n",
    "    edge_flows: EdgeFlows = defaultdict(float)\n",
    "\n",
    "    # sample new agents\n",
    "    if od_mode == \"random\":\n",
    "        agents = sample_agents_random(network, num_agents)\n",
    "    elif od_mode == \"north_south\":\n",
    "        agents = sample_agents_north_south(network, num_agents)\n",
    "    else:  # \"fixed\" or anything else -> use fixed OD\n",
    "        agents = sample_agents_fixed(network, num_agents, origin, destination)\n",
    "\n",
    "    for agent in agents:\n",
    "        s = agent.origin\n",
    "        d = agent.destination\n",
    "        path = [s]\n",
    "        steps = 0\n",
    "\n",
    "        while s != d and steps < max_steps_per_agent:\n",
    "            neighbors = get_neighbors(network, s)\n",
    "            if not neighbors:\n",
    "                break\n",
    "\n",
    "            # greedy: epsilon = 0\n",
    "            best_q = None\n",
    "            best_actions = []\n",
    "            for a in neighbors:\n",
    "                key = (s, d, a)\n",
    "                q = Q.get(key, 0.0)\n",
    "                if best_q is None or q > best_q:\n",
    "                    best_q = q\n",
    "                    best_actions = [a]\n",
    "                elif q == best_q:\n",
    "                    best_actions.append(a)\n",
    "\n",
    "            a = random.choice(best_actions)\n",
    "\n",
    "            edge_id = (s, a)\n",
    "            if edge_id not in network.edges:\n",
    "                break\n",
    "\n",
    "            edge_flows[edge_id] += 1.0\n",
    "            s = a\n",
    "            path.append(s)\n",
    "            steps += 1\n",
    "\n",
    "        agent.path = path\n",
    "\n",
    "    G = total_system_travel_time(network, edge_flows)\n",
    "    return agents, edge_flows, G\n",
    "\n"
   ],
   "id": "3e0127e97d1c9c09",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Experiment wrappers",
   "id": "5a479e66cc9cf85f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### SPA Experiment",
   "id": "4e3b17c575f9227c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def run_spa_experiment(network: TrafficNetwork,\n",
    "                       num_agents: int = 500,\n",
    "                       od_mode: str = \"north_south\") -> Tuple[List[Agent], EdgeFlows, float]:\n",
    "    if od_mode == \"random\":\n",
    "        agents = sample_agents_random(network, num_agents)\n",
    "    elif od_mode in (\"north_south\", \"north-south\"):\n",
    "        agents = sample_agents_north_south(network, num_agents)\n",
    "    elif od_mode == \"fixed\":\n",
    "        agents = sample_agents_fixed(network, num_agents, origin, destination)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown od_mode: {od_mode}\")\n",
    "\n",
    "    agents, edge_flows = spa_route_all(network, agents)\n",
    "    G = total_system_travel_time(network, edge_flows)\n",
    "\n",
    "    print(f\"SPA experiment with {num_agents} agents ({od_mode} O/D)\")\n",
    "    print(f\"Total system travel time G: {G:.2f}\")\n",
    "    print(f\"Used edges: {len([e for e, f in edge_flows.items() if f > 0])} / {len(network.edges)}\")\n",
    "\n",
    "    return agents, edge_flows, G\n"
   ],
   "id": "8ec3308800f7354d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## FF Experiment",
   "id": "57b3951ab193ba7b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def run_ff_experiment(network,\n",
    "                           num_agents: int = 500,\n",
    "                           od_mode: str = \"fixed\"):\n",
    "    \"\"\"\n",
    "    Ford–Fulkerson style COIN experiment:\n",
    "    routes agents using ff_route_all and computes world utility G.\n",
    "    \"\"\"\n",
    "    if od_mode == \"random\":\n",
    "        agents = sample_agents_random(network, num_agents)\n",
    "    elif od_mode in (\"north_south\", \"north-south\"):\n",
    "        agents = sample_agents_north_south(network, num_agents)\n",
    "    else:  # \"fixed\"\n",
    "        agents = sample_agents_fixed(network, num_agents, origin, destination)\n",
    "\n",
    "    agents, edge_flows = ff_route_all(network, agents)\n",
    "    G = total_system_travel_time(network, edge_flows)\n",
    "\n",
    "    print(f\"FF experiment with {num_agents} agents ({od_mode} O/D)\")\n",
    "    print(f\"Total system travel time G_COIN_FF: {G:.2f}\")\n",
    "    print(f\"Used edges: {len([e for e,f in edge_flows.items() if f > 0])} / {len(network.edges)}\")\n",
    "\n",
    "    return agents, edge_flows, G"
   ],
   "id": "e671fd63938c37ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## FF COIN EXperiment",
   "id": "47e263ccb7a5eb88"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# === COIN-FF → Expert Dataset for Imitation Learning =====================\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def build_coin_ff_expert_dataset(\n",
    "    network: TrafficNetwork,\n",
    "    num_agents: int = 200,\n",
    "    od_mode: str = \"fixed\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Run COIN-FF once and record (state, dest, action) triples\n",
    "    from the COIN-FF paths. This is our 'expert' dataset.\n",
    "\n",
    "    We ONLY keep steps from agents that actually reach their destination,\n",
    "    to avoid teaching RL to wander or get stuck.\n",
    "    \"\"\"\n",
    "    # Sample agents according to od_mode\n",
    "    if od_mode == \"random\":\n",
    "        agents = sample_agents_random(network, num_agents)\n",
    "    elif od_mode in (\"north_south\", \"north-south\"):\n",
    "        agents = sample_agents_north_south(network, num_agents)\n",
    "    else:  # \"fixed\"\n",
    "        agents = sample_agents_fixed(network, num_agents, origin, destination)\n",
    "\n",
    "    # Route them with COIN-FF (this updates edge_flows internally)\n",
    "    agents_ff, edge_flows_ff = ff_route_all(network, agents)\n",
    "\n",
    "    expert_triples = []  # list of (state_node, dest_node, action_node)\n",
    "\n",
    "    for agent in agents_ff:\n",
    "        # keep only successful trajectories\n",
    "        if not agent.path or agent.path[-1] != agent.destination:\n",
    "            continue\n",
    "        d = agent.destination\n",
    "        for (s, a) in edges_from_path(agent.path):\n",
    "            expert_triples.append((s, d, a))\n",
    "\n",
    "    print(f\"Collected {len(expert_triples)} expert (s,d,a) triples \"\n",
    "          f\"from {len(agents_ff)} COIN-FF agents.\")\n",
    "    return expert_triples"
   ],
   "id": "15a26ef94caa95a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train Q from COIN-FF Expert",
   "id": "4a93b334aa5fb16c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# === Train Q from COIN-FF expert (Behavior Cloning) ======================\n",
    "\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "def train_q_from_coin_ff_expert(\n",
    "    expert_triples,\n",
    "    alpha_bc: float = 0.5\n",
    ") -> Dict[Tuple[Node, Node, Node], float]:\n",
    "    \"\"\"\n",
    "    Simple behavior-cloning style 'RL':\n",
    "    For each expert (s, d, a) triple we push Q(s,d,a) toward 1.0.\n",
    "\n",
    "    Later, route_with_trained_Q will act greedily wrt Q and\n",
    "    (ideally) reproduce COIN-FF decisions.\n",
    "    \"\"\"\n",
    "    Q: Dict[Tuple[Node, Node, Node], float] = {}\n",
    "\n",
    "    for (s, d, a) in expert_triples:\n",
    "        key = (s, d, a)\n",
    "        old_q = Q.get(key, 0.0)\n",
    "        target = 1.0                # \"expert\" value\n",
    "        Q[key] = old_q + alpha_bc * (target - old_q)\n",
    "\n",
    "    print(f\"Trained Q on {len(expert_triples)} expert steps \"\n",
    "          f\"(unique state-action pairs: {len(Q)}).\")\n",
    "    return Q"
   ],
   "id": "8847c6fa4675a5f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Coin rl from expert FF",
   "id": "a7ddc62bd0b1b871"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# === Experiment: SPA vs COIN-FF vs COIN-RL(BC) ===========================\n",
    "\n",
    "def run_coin_rl_from_expert_experiment(\n",
    "    network: TrafficNetwork,\n",
    "    num_agents_spa: int = 100,\n",
    "    num_agents_expert: int = 200,\n",
    "    num_agents_eval_rl: int = 100,\n",
    "    od_mode: str = \"fixed\"\n",
    "):\n",
    "    \"\"\"\n",
    "    1) SPA baseline\n",
    "    2) COIN-FF expert (used only to generate dataset)\n",
    "    3) COIN-RL(BC): Q-policy trained to imitate COIN-FF,\n",
    "       then evaluated on fresh agents with route_with_trained_Q.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 1) SPA baseline ---\n",
    "    agents_spa, flows_spa, G_spa = run_spa_experiment(\n",
    "        network,\n",
    "        num_agents=num_agents_spa,\n",
    "        od_mode=od_mode\n",
    "    )\n",
    "\n",
    "    # --- 2) COIN-FF expert dataset ---\n",
    "    expert_triples = build_coin_ff_expert_dataset(\n",
    "        network,\n",
    "        num_agents=num_agents_expert,\n",
    "        od_mode=od_mode\n",
    "    )\n",
    "    Q_rl = train_q_from_coin_ff_expert(expert_triples, alpha_bc=0.5)\n",
    "\n",
    "    # --- 3) Evaluate RL policy learned from expert ---\n",
    "    agents_rl, flows_rl, G_rl = route_with_trained_Q(\n",
    "        network=network,\n",
    "        Q=Q_rl,\n",
    "        num_agents=num_agents_eval_rl,\n",
    "        od_mode=od_mode,\n",
    "        max_steps_per_agent=1500   # reuse your previous limit\n",
    "    )\n",
    "\n",
    "    print(\"\\n=== Summary: SPA vs COIN-RL(BC) ===\")\n",
    "    print(f\"G_SPA      = {G_spa:.2f}\")\n",
    "    print(f\"G_RL(BC)   = {G_rl:.2f}\")\n",
    "    print(f\"Improvement (RL vs SPA) = {(G_spa - G_rl) / G_spa * 100:.2f}%\")\n",
    "\n",
    "    return (agents_spa, flows_spa, G_spa,\n",
    "            agents_rl,  flows_rl,  G_rl,\n",
    "            Q_rl)"
   ],
   "id": "92d37fbd52a24fe0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Coin Experiment",
   "id": "95c4df76cc8ec3cd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def run_coin_experiment_rl(\n",
    "    network: TrafficNetwork,\n",
    "    num_agents: int = 500,\n",
    "    od_mode: str = \"fixed\",\n",
    "    episodes: int = 200,\n",
    "    alpha: float = 0.1,\n",
    "    gamma: float = 0.95,\n",
    "    epsilon_start: float = 0.9,\n",
    "    epsilon_end: float = 0.05,\n",
    "    max_steps_per_agent: int = 1500,\n",
    "    seed: Optional[int] = 42\n",
    ") -> Tuple[Dict[Tuple[Node, Node, Node], float], List[Agent], EdgeFlows, float]:\n",
    "    \"\"\"\n",
    "    Train a COIN-style RL policy and evaluate it on a fresh set of agents.\n",
    "    Returns: Q, agents_coin, edge_flows_coin, G_coin\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "\n",
    "    print(\"=== Training COIN-RL policy ===\")\n",
    "    Q = train_coin_rl(\n",
    "        network=network,\n",
    "        episodes=episodes,\n",
    "        num_agents=num_agents,\n",
    "        od_mode=od_mode,\n",
    "        alpha=alpha,\n",
    "        gamma=gamma,\n",
    "        epsilon_start=epsilon_start,\n",
    "        epsilon_end=epsilon_end,\n",
    "        max_steps_per_agent=max_steps_per_agent,\n",
    "    )\n",
    "\n",
    "    print(\"\\n=== Evaluating COIN-RL policy ===\")\n",
    "    agents_coin, edge_flows_coin, G_coin = route_with_trained_Q(\n",
    "        network=network,\n",
    "        Q=Q,\n",
    "        num_agents=num_agents,\n",
    "        od_mode=od_mode,\n",
    "        max_steps_per_agent=max_steps_per_agent,\n",
    "    )\n",
    "\n",
    "    print(f\"COIN-RL experiment with {num_agents} agents ({od_mode} O/D)\")\n",
    "    print(f\"Total system travel time G_COIN_RL: {G_coin:.2f}\")\n",
    "    print(f\"Used edges: {len([e for e, f in edge_flows_coin.items() if f > 0])} / {len(network.edges)}\")\n",
    "\n",
    "    return Q, agents_coin, edge_flows_coin, G_coin\n"
   ],
   "id": "44ea9b9ea775a62b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Run main experiments",
   "id": "e86216c845684cbb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Fraction of agents that actually reach destination\n",
    "def fraction_reached(agents, dest):\n",
    "    reached = sum(1 for a in agents if a.path and a.path[-1] == dest)\n",
    "    return reached / len(agents)"
   ],
   "id": "667ef5665d8baab5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### SPA vs  FF",
   "id": "13e6147ad3de268a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "random.seed(42)\n",
    "\n",
    "num_agents = 100  # or 100, whatever you prefer\n",
    "\n",
    "# SPA baseline (fixed OD so it's comparable)\n",
    "agents_spa, flows_spa, G_spa = run_spa_experiment(\n",
    "    manhattan_network,\n",
    "    num_agents=num_agents,\n",
    "    od_mode=\"fixed\"\n",
    ")\n",
    "\n",
    "# COIN baseline using Ford–Fulkerson-style marginal-cost routing\n",
    "agents_ff, flows_ff, G_ff = run_ff_experiment(\n",
    "    manhattan_network,\n",
    "    num_agents=num_agents,\n",
    "    od_mode=\"fixed\"\n",
    ")\n",
    "\n",
    "print(f\"\\nG_SPA      = {G_spa:.2f}\")\n",
    "print(f\"G_COIN_FF  = {G_ff:.2f}\")\n",
    "print(f\"Improvement = {(G_spa - G_ff) / G_spa * 100:.2f}%\")"
   ],
   "id": "8906f399181919cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def fraction_reached(agents, dest):\n",
    "    reached = sum(1 for a in agents if a.path and a.path[-1] == dest)\n",
    "    return reached / len(agents)\n",
    "\n",
    "print(\"SPA fraction reaching dest:\", fraction_reached(agents_spa, destination))\n",
    "print(\"COIN fraction reaching dest:\", fraction_reached(agents_ff, destination))"
   ],
   "id": "5dcf76fe628c6072",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### SPA VS COIN",
   "id": "b648ba94a353dafe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "random.seed(42)\n",
    "\n",
    "(agents_spa, flows_spa, G_spa,\n",
    " agents_coin_ff_rl,  flows_coin_fl_rl,  G_coin_ff_rl,\n",
    " Q_rl) = run_coin_rl_from_expert_experiment(\n",
    "    manhattan_network,\n",
    "    num_agents_spa=100,\n",
    "    num_agents_expert=200,\n",
    "    num_agents_eval_rl=100,\n",
    "    od_mode=\"fixed\"   # same OD as your COIN-FF\n",
    ")\n",
    "\n",
    "print(\"\\nSPA fraction reaching dest: \",\n",
    "      fraction_reached(agents_spa, destination))\n",
    "print(\"RL(BC) fraction reaching dest: \",\n",
    "      fraction_reached(agents_coin_ff_rl, destination))"
   ],
   "id": "deb24b194495d006",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Per-agent travel times",
   "id": "4d594dfa08e5849e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compute_agent_travel_times(network: TrafficNetwork,\n",
    "                               edge_flows: EdgeFlows,\n",
    "                               agents: List[Agent]) -> List[float]:\n",
    "    times = []\n",
    "    for agent in agents:\n",
    "        if not agent.path or len(agent.path) < 2:\n",
    "            times.append(0.0)\n",
    "            continue\n",
    "        total = 0.0\n",
    "        for u, v in edges_from_path(agent.path):\n",
    "            edge = network.edges[(u, v)]\n",
    "            flow = edge_flows[(u, v)]\n",
    "            total += edge.travel_time(flow)\n",
    "        times.append(total)\n",
    "    return times\n",
    "\n",
    "spa_times = compute_agent_travel_times(manhattan_network, flows_spa, agents_spa)\n",
    "ff_times = compute_agent_travel_times(manhattan_network, flows_ff, agents_ff)\n",
    "\n",
    "print(\"SPA avg time:\", sum(spa_times) / len(spa_times))\n",
    "print(\"COIN-RL avg time:\", sum(ff_times) / len(ff_times))\n"
   ],
   "id": "e6c3a14f2018a226",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Visualization helpers",
   "id": "e65a02998abe98a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def routes_to_gdf(agents: List[Agent], crs) -> gpd.GeoDataFrame:\n",
    "    geoms = []\n",
    "    for agent in agents:\n",
    "        if agent.path is not None and len(agent.path) > 1:\n",
    "            geoms.append(LineString(agent.path))\n",
    "    return gpd.GeoDataFrame(geometry=geoms, crs=crs)\n",
    "\n",
    "def edge_flows_to_gdf(edge_flows: EdgeFlows,\n",
    "                      network: TrafficNetwork,\n",
    "                      crs) -> gpd.GeoDataFrame:\n",
    "    geoms = []\n",
    "    flows = []\n",
    "    for (u, v), f in edge_flows.items():\n",
    "        if f <= 0:\n",
    "            continue\n",
    "        geoms.append(LineString([u, v]))\n",
    "        flows.append(f)\n",
    "    return gpd.GeoDataFrame({\"flow\": flows}, geometry=geoms, crs=crs)\n"
   ],
   "id": "81098648081daf4d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "SPA vs FF routes",
   "id": "5e5b8caa9f113558"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "routes_spa = routes_to_gdf(agents_spa, crs=gdf.crs)\n",
    "routes_ff = routes_to_gdf(agents_ff, crs=gdf.crs)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 8))\n",
    "\n",
    "# SPA routes\n",
    "gdf.plot(ax=axes[0], linewidth=0.3, color=\"lightgray\")\n",
    "routes_spa.plot(ax=axes[0], linewidth=1.2, alpha=0.9)\n",
    "axes[0].set_title(f\"SPA routes (G = {G_spa:.1f})\")\n",
    "axes[0].set_axis_off()\n",
    "\n",
    "# COIN routes\n",
    "gdf.plot(ax=axes[1], linewidth=0.3, color=\"lightgray\")\n",
    "routes_ff.plot(ax=axes[1], linewidth=1.2, alpha=0.9)\n",
    "axes[1].set_title(f\"FF routes (G = {G_ff:.1f})\")\n",
    "axes[1].set_axis_off()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "ebca4f39de4b8973",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "SPA vs FF heatmaps",
   "id": "81e62db81dda93b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "flows_spa_gdf = edge_flows_to_gdf(flows_spa, manhattan_network, crs=gdf.crs)\n",
    "flows_ff_gdf = edge_flows_to_gdf(flows_ff, manhattan_network, crs=gdf.crs)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 8))\n",
    "\n",
    "# SPA heatmap\n",
    "gdf.plot(ax=axes[0], linewidth=0.2, color=\"lightgray\")\n",
    "flows_spa_gdf.plot(\n",
    "    ax=axes[0],\n",
    "    column=\"flow\",\n",
    "    linewidth=2,\n",
    "    alpha=0.9,\n",
    "    legend=True\n",
    ")\n",
    "axes[0].set_title(\"SPA edge flows\")\n",
    "axes[0].set_axis_off()\n",
    "\n",
    "# COIN heatmap\n",
    "gdf.plot(ax=axes[1], linewidth=0.2, color=\"lightgray\")\n",
    "flows_ff_gdf.plot(\n",
    "    ax=axes[1],\n",
    "    column=\"flow\",\n",
    "    linewidth=2,\n",
    "    alpha=0.9,\n",
    "    legend=True\n",
    ")\n",
    "axes[1].set_title(\"FF edge flows\")\n",
    "axes[1].set_axis_off()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "7d850530e88e4faa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## SPA vs Coin FF",
   "id": "547b66b9f9957805"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "routes_spa = routes_to_gdf(agents_spa, crs=gdf.crs)\n",
    "routes_coin_ff_rl = routes_to_gdf(agents_coin_ff_rl, crs=gdf.crs)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 8))\n",
    "\n",
    "# SPA routes\n",
    "gdf.plot(ax=axes[0], linewidth=0.3, color=\"lightgray\")\n",
    "routes_spa.plot(ax=axes[0], linewidth=1.2, alpha=0.9)\n",
    "axes[0].set_title(f\"SPA routes (G = {G_spa:.1f})\")\n",
    "axes[0].set_axis_off()\n",
    "\n",
    "# COIN routes\n",
    "gdf.plot(ax=axes[1], linewidth=0.3, color=\"lightgray\")\n",
    "routes_coin_ff_rl.plot(ax=axes[1], linewidth=1.2, alpha=0.9)\n",
    "axes[1].set_title(f\"Coin FF expert routes (G = {G_coin_ff_rl:.1f})\")\n",
    "axes[1].set_axis_off()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "3aa2875fa8676054",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## SPA vs COIN FF Heatmap",
   "id": "bf03d497b23702fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "flows_spa_gdf = edge_flows_to_gdf(flows_spa, manhattan_network, crs=gdf.crs)\n",
    "flows_coin_ff_gdf = edge_flows_to_gdf(flows_coin_fl_rl, manhattan_network, crs=gdf.crs)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 8))\n",
    "\n",
    "# SPA heatmap\n",
    "gdf.plot(ax=axes[0], linewidth=0.2, color=\"lightgray\")\n",
    "flows_spa_gdf.plot(\n",
    "    ax=axes[0],\n",
    "    column=\"flow\",\n",
    "    linewidth=2,\n",
    "    alpha=0.9,\n",
    "    legend=True\n",
    ")\n",
    "axes[0].set_title(\"SPA edge flows\")\n",
    "axes[0].set_axis_off()\n",
    "\n",
    "# COIN heatmap\n",
    "gdf.plot(ax=axes[1], linewidth=0.2, color=\"lightgray\")\n",
    "flows_coin_ff_gdf.plot(\n",
    "    ax=axes[1],\n",
    "    column=\"flow\",\n",
    "    linewidth=2,\n",
    "    alpha=0.9,\n",
    "    legend=True\n",
    ")\n",
    "axes[1].set_title(\"COIN FF edge flows\")\n",
    "axes[1].set_axis_off()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "4e4669e4de7392da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ce6954ff6a3ebc4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4869e2990aa6e58f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
